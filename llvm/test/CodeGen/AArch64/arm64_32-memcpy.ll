; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mtriple=arm64_32-apple-ios9.0 -o - %s | FileCheck %s

define i64 @test_memcpy(i64* %addr, i8* %src, i1 %tst) minsize {
; CHECK-LABEL: test_memcpy:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    stp x20, x19, [sp, #-32]! ; 16-byte Folded Spill
; CHECK-NEXT:    .cfi_def_cfa_offset 32
; CHECK-NEXT:    stp x29, x30, [sp, #16] ; 16-byte Folded Spill
; CHECK-NEXT:    .cfi_offset w30, -8
; CHECK-NEXT:    .cfi_offset w29, -16
; CHECK-NEXT:    .cfi_offset w19, -24
; CHECK-NEXT:    .cfi_offset w20, -32
; CHECK-NEXT:    ldr x19, [x0]
; CHECK-NEXT:    tbnz w2, #0, LBB0_2
; CHECK-NEXT:  ; %bb.1: ; %false
; CHECK-NEXT:    mov w0, w19
; CHECK-NEXT:    mov w2, #128
; CHECK-NEXT:    bl _memcpy
; CHECK-NEXT:  LBB0_2: ; %common.ret
; CHECK-NEXT:    ldp x29, x30, [sp, #16] ; 16-byte Folded Reload
; CHECK-NEXT:    b _OUTLINED_FUNCTION_0
; [...]

  %val64 = load i64, i64* %addr
  br i1 %tst, label %true, label %false

true:
  ret i64 %val64

false:
  %val32 = trunc i64 %val64 to i32
  %val.ptr = inttoptr i32 %val32 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i32(i8* %val.ptr, i8* %src, i32 128, i32 0, i1 1)
  ret i64 undef
}

define i64 @test_memmove(i64* %addr, i8* %src, i1 %tst) minsize {
; CHECK-LABEL: test_memmove:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    stp x20, x19, [sp, #-32]! ; 16-byte Folded Spill
; CHECK-NEXT:    .cfi_def_cfa_offset 32
; CHECK-NEXT:    stp x29, x30, [sp, #16] ; 16-byte Folded Spill
; CHECK-NEXT:    .cfi_offset w30, -8
; CHECK-NEXT:    .cfi_offset w29, -16
; CHECK-NEXT:    .cfi_offset w19, -24
; CHECK-NEXT:    .cfi_offset w20, -32
; CHECK-NEXT:    ldr x19, [x0]
; CHECK-NEXT:    tbnz w2, #0, LBB1_2
; CHECK-NEXT:  ; %bb.1: ; %false
; CHECK-NEXT:    mov w0, w19
; CHECK-NEXT:    mov w2, #128
; CHECK-NEXT:    bl _memmove
; CHECK-NEXT:  LBB1_2: ; %common.ret
; CHECK-NEXT:    ldp x29, x30, [sp, #16] ; 16-byte Folded Reload
; CHECK-NEXT:    b _OUTLINED_FUNCTION_0
; [...]

  %val64 = load i64, i64* %addr
  br i1 %tst, label %true, label %false

true:
  ret i64 %val64

false:
  %val32 = trunc i64 %val64 to i32
  %val.ptr = inttoptr i32 %val32 to i8*
  call void @llvm.memmove.p0i8.p0i8.i32(i8* %val.ptr, i8* %src, i32 128, i32 0, i1 1)
  ret i64 undef
}

define i64 @test_memset(i64* %addr, i8* %src, i1 %tst) minsize {
; CHECK-LABEL: test_memset:
; CHECK:       ; %bb.0:
; CHECK-NEXT:    stp x20, x19, [sp, #-32]! ; 16-byte Folded Spill
; CHECK-NEXT:    .cfi_def_cfa_offset 32
; CHECK-NEXT:    stp x29, x30, [sp, #16] ; 16-byte Folded Spill
; CHECK-NEXT:    .cfi_offset w30, -8
; CHECK-NEXT:    .cfi_offset w29, -16
; CHECK-NEXT:    .cfi_offset w19, -24
; CHECK-NEXT:    .cfi_offset w20, -32
; CHECK-NEXT:    ldr x19, [x0]
; CHECK-NEXT:    tbnz w2, #0, LBB2_2
; CHECK-NEXT:  ; %bb.1: ; %false
; CHECK-NEXT:    mov w0, w19
; CHECK-NEXT:    mov w1, #42
; CHECK-NEXT:    mov w2, #256
; CHECK-NEXT:    bl _memset
; CHECK-NEXT:  LBB2_2: ; %common.ret
; CHECK-NEXT:    ldp x29, x30, [sp, #16] ; 16-byte Folded Reload
; CHECK-NEXT:    b _OUTLINED_FUNCTION_0
; [...]

  %val64 = load i64, i64* %addr
  br i1 %tst, label %true, label %false

true:
  ret i64 %val64

false:
  %val32 = trunc i64 %val64 to i32
  %val.ptr = inttoptr i32 %val32 to i8*
  call void @llvm.memset.p0i8.i32(i8* %val.ptr, i8 42, i32 256, i32 0, i1 1)
  ret i64 undef
}

declare void @llvm.memcpy.p0i8.p0i8.i32(i8*, i8*, i32, i32, i1)
declare void @llvm.memmove.p0i8.p0i8.i32(i8*, i8*, i32, i32, i1)
declare void @llvm.memset.p0i8.i32(i8*, i8, i32, i32, i1)

