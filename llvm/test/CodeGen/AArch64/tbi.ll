; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -aarch64-use-tbi -mtriple=arm64-apple-ios8.0.0 < %s \
; RUN:     | FileCheck --check-prefix=TBI    --check-prefix=BOTH %s
; RUN: llc -aarch64-use-tbi -mtriple=arm64-apple-ios7.1.0 < %s \
; RUN:     | FileCheck --check-prefix=NO_TBI --check-prefix=BOTH %s

; BOTH-LABEL:ld_and32:
; TBI-NOT: and x
; NO_TBI: and x
define i32 @ld_and32(i64 %p) {
; TBI-LABEL: ld_and32:
; TBI:       ; %bb.0:
; TBI-NEXT:    ldr w0, [x0]
; TBI-NEXT:    ret
;
; NO_TBI-LABEL: ld_and32:
; NO_TBI:       ; %bb.0:
; NO_TBI-NEXT:    and x8, x0, #0xffffffffffffff
; NO_TBI-NEXT:    ldr w0, [x8]
; NO_TBI-NEXT:    ret
  %and = and i64 %p, 72057594037927935
  %cast = inttoptr i64 %and to i32*
  %load = load i32, i32* %cast
  ret i32 %load
}

; load (r & MASK) + 4
; BOTH-LABEL:ld_and_plus_offset:
; TBI-NOT: and x
; NO_TBI: and x
define i32 @ld_and_plus_offset(i64 %p) {
; TBI-LABEL: ld_and_plus_offset:
; TBI:       ; %bb.0:
; TBI-NEXT:    ldr w0, [x0, #16]
; TBI-NEXT:    ret
;
; NO_TBI-LABEL: ld_and_plus_offset:
; NO_TBI:       ; %bb.0:
; NO_TBI-NEXT:    and x8, x0, #0xffffffffffffff
; NO_TBI-NEXT:    ldr w0, [x8, #16]
; NO_TBI-NEXT:    ret
  %and = and i64 %p, 72057594037927935
  %cast = inttoptr i64 %and to i32*
  %gep = getelementptr i32, i32* %cast, i64 4
  %load = load i32, i32* %gep
  ret i32 %load
}

; load (r & WIDER_MASK)
; BOTH-LABEL:ld_and32_wider:
; TBI-NOT: and x
; NO_TBI: and x
define i32 @ld_and32_wider(i64 %p) {
; TBI-LABEL: ld_and32_wider:
; TBI:       ; %bb.0:
; TBI-NEXT:    ldr w0, [x0]
; TBI-NEXT:    ret
;
; NO_TBI-LABEL: ld_and32_wider:
; NO_TBI:       ; %bb.0:
; NO_TBI-NEXT:    and x8, x0, #0xfffffffffffffff
; NO_TBI-NEXT:    ldr w0, [x8]
; NO_TBI-NEXT:    ret
  %and = and i64 %p, 1152921504606846975
  %cast = inttoptr i64 %and to i32*
  %load = load i32, i32* %cast
  ret i32 %load
}

; BOTH-LABEL:ld_and64:
; TBI-NOT: and x
; NO_TBI: and x
define i64 @ld_and64(i64 %p) {
; TBI-LABEL: ld_and64:
; TBI:       ; %bb.0:
; TBI-NEXT:    ldr x0, [x0]
; TBI-NEXT:    ret
;
; NO_TBI-LABEL: ld_and64:
; NO_TBI:       ; %bb.0:
; NO_TBI-NEXT:    and x8, x0, #0xffffffffffffff
; NO_TBI-NEXT:    ldr x0, [x8]
; NO_TBI-NEXT:    ret
  %and = and i64 %p, 72057594037927935
  %cast = inttoptr i64 %and to i64*
  %load = load i64, i64* %cast
  ret i64 %load
}

; BOTH-LABEL:st_and32:
; TBI-NOT: and x
; NO_TBI: and x
define void @st_and32(i64 %p, i32 %v) {
; TBI-LABEL: st_and32:
; TBI:       ; %bb.0:
; TBI-NEXT:    str w1, [x0]
; TBI-NEXT:    ret
;
; NO_TBI-LABEL: st_and32:
; NO_TBI:       ; %bb.0:
; NO_TBI-NEXT:    and x8, x0, #0xffffffffffffff
; NO_TBI-NEXT:    str w1, [x8]
; NO_TBI-NEXT:    ret
  %and = and i64 %p, 72057594037927935
  %cast = inttoptr i64 %and to i32*
  store i32 %v, i32* %cast
  ret void
}

; load (x1 + x2) & MASK
; BOTH-LABEL:ld_ro:
; TBI-NOT: and x
; NO_TBI: and x
define i32 @ld_ro(i64 %a, i64 %b) {
; TBI-LABEL: ld_ro:
; TBI:       ; %bb.0:
; TBI-NEXT:    ldr w0, [x0, x1]
; TBI-NEXT:    ret
;
; NO_TBI-LABEL: ld_ro:
; NO_TBI:       ; %bb.0:
; NO_TBI-NEXT:    add x8, x0, x1
; NO_TBI-NEXT:    and x8, x8, #0xffffffffffffff
; NO_TBI-NEXT:    ldr w0, [x8]
; NO_TBI-NEXT:    ret
  %p = add i64 %a, %b
  %and = and i64 %p, 72057594037927935
  %cast = inttoptr i64 %and to i32*
  %load = load i32, i32* %cast
  ret i32 %load
}

; load (r1 & MASK) + r2
; BOTH-LABEL:ld_ro2:
; TBI-NOT: and x
; NO_TBI: and x
define i32 @ld_ro2(i64 %a, i64 %b) {
; TBI-LABEL: ld_ro2:
; TBI:       ; %bb.0:
; TBI-NEXT:    ldr w0, [x0, x1]
; TBI-NEXT:    ret
;
; NO_TBI-LABEL: ld_ro2:
; NO_TBI:       ; %bb.0:
; NO_TBI-NEXT:    and x8, x0, #0xffffffffffffff
; NO_TBI-NEXT:    ldr w0, [x8, x1]
; NO_TBI-NEXT:    ret
  %and = and i64 %a, 72057594037927935
  %p = add i64 %and, %b
  %cast = inttoptr i64 %p to i32*
  %load = load i32, i32* %cast
  ret i32 %load
}

; load (r1 & MASK) | r2
; BOTH-LABEL:ld_indirect_and:
; TBI-NOT: and x
; NO_TBI: and x
define i32 @ld_indirect_and(i64 %r1, i64 %r2) {
; TBI-LABEL: ld_indirect_and:
; TBI:       ; %bb.0:
; TBI-NEXT:    orr x8, x0, x1
; TBI-NEXT:    ldr w0, [x8]
; TBI-NEXT:    ret
;
; NO_TBI-LABEL: ld_indirect_and:
; NO_TBI:       ; %bb.0:
; NO_TBI-NEXT:    and x8, x0, #0xffffffffffffff
; NO_TBI-NEXT:    orr x8, x8, x1
; NO_TBI-NEXT:    ldr w0, [x8]
; NO_TBI-NEXT:    ret
  %and = and i64 %r1, 72057594037927935
  %p = or i64 %and, %r2
  %cast = inttoptr i64 %p to i32*
  %load = load i32, i32* %cast
  ret i32 %load
}

; BOTH-LABEL:ld_and32_narrower:
; BOTH: and x
define i32 @ld_and32_narrower(i64 %p) {
; TBI-LABEL: ld_and32_narrower:
; TBI:       ; %bb.0:
; TBI-NEXT:    and x8, x0, #0x7fffffffffffff
; TBI-NEXT:    ldr w0, [x8]
; TBI-NEXT:    ret
;
; NO_TBI-LABEL: ld_and32_narrower:
; NO_TBI:       ; %bb.0:
; NO_TBI-NEXT:    and x8, x0, #0x7fffffffffffff
; NO_TBI-NEXT:    ldr w0, [x8]
; NO_TBI-NEXT:    ret
  %and = and i64 %p, 36028797018963967
  %cast = inttoptr i64 %and to i32*
  %load = load i32, i32* %cast
  ret i32 %load
}

; BOTH-LABEL:ld_and8:
; BOTH: and x
define i32 @ld_and8(i64 %base, i8 %off) {
; TBI-LABEL: ld_and8:
; TBI:       ; %bb.0:
; TBI-NEXT:    and w8, w1, #0x3f
; TBI-NEXT:    ldr w0, [x0, w8, uxtw]
; TBI-NEXT:    ret
;
; NO_TBI-LABEL: ld_and8:
; NO_TBI:       ; %bb.0:
; NO_TBI-NEXT:    and w8, w1, #0x3f
; NO_TBI-NEXT:    ldr w0, [x0, w8, uxtw]
; NO_TBI-NEXT:    ret
  %off_masked = and i8 %off, 63
  %off_64 = zext i8 %off_masked to i64
  %p = add i64 %base, %off_64
  %cast = inttoptr i64 %p to i32*
  %load = load i32, i32* %cast
  ret i32 %load
}
;; NOTE: These prefixes are unused and the list is autogenerated. Do not add tests below this line:
; BOTH: {{.*}}
